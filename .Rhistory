setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# Set working directory
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# Import data
dat1 <- read.csv("xcmsresults.csv", header=T, row.names=1,)
# Set working directory
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# Import data
dat1 <- read.csv("DryAlmondDryPistachio.csv", header=T, row.names=1,)
View(dat1)
View(dat1)
dat1[1:6,1:4]  # look at the first few rows
#ck the structure of the data frame needs to be num
str(dat1)
# This function will find the minimum value greater than zero
# and divide that value by two
replacezero = function(x) "[<-"(x, !x | is.na(x), min(x[x > 0], na.rm = TRUE) / 2)
# Apply function across rows
dat2 <- as.data.frame(t(apply(dat1, 1, replacezero)))
dat2[1:6,1:4]  # look at the first few rows
# Set working directory
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# Import data
dat1 <- read.csv("DryAlmondDryPistachio.csv", header=T, row.names=1,)
dat1[1:6,1:4]  # look at the first few rows
#ck the structure of the data frame needs to be num
str(dat1)
# This function will find the minimum value greater than zero
# and divide that value by two
replacezero = function(x) "[<-"(x, !x | is.na(x), min(x[x > 0], na.rm = TRUE) / 2)
# Apply function across rows
dat2 <- as.data.frame(t(apply(dat1, 1, replacezero)))
dat2[1:6,1:4]  # look at the first few rows
# Log transform the data (base 2 log)
logdata <- log(dat2, 2)
# Function for pareto scaling
paretoscale <- function(z) {
rowmean <- apply(z, 1, mean) # row means
rowsd <- apply(z, 1, sd)  # row standard deviation
rowsqrtsd <- sqrt(rowsd) # sqrt of sd
rv <- sweep(z, 1, rowmean,"-")  # mean center
rv <- sweep(rv, 1, rowsqrtsd, "/")  # dividing by sqrtsd
return(rv)
}
# Pareto scale log transformed data
logdata.pareto <- paretoscale(logdata)
# Import data
dat1 <- read.csv("DryAlmondDryPistachio.csv", header=T, row.names=1,)
dat1[1:6,1:4]  # look at the first few rows
#ck the structure of the data frame needs to be num
str(dat1)
# This function will find the minimum value greater than zero
# and divide that value by two
replacezero = function(x) "[<-"(x, !x | is.na(x), min(x[x > 0], na.rm = TRUE) / 2)
# Apply function across rows
dat2 <- as.data.frame(t(apply(dat1, 1, replacezero)))
dat2[1:6,1:4]  # look at the first few rows
# Log transform the data (base 2 log)
logdata <- log(dat2, 2)
# Function for pareto scaling
paretoscale <- function(z) {
rowmean <- apply(z, 1, mean) # row means
rowsd <- apply(z, 1, sd)  # row standard deviation
rowsqrtsd <- sqrt(rowsd) # sqrt of sd
rv <- sweep(z, 1, rowmean,"-")  # mean center
rv <- sweep(rv, 1, rowsqrtsd, "/")  # dividing by sqrtsd
return(rv)
}
# Pareto scale log transformed data
logdata.pareto <- paretoscale(logdata)
# Run PCA (note use of "t" to transpose matrix)
pca <- prcomp(t(logdata.pareto), center=F, scale=F)
# Create a container called "results" for PCA results
results <- summary(pca)
results$importance  # summary table of explained variance
results$x           # scores matrix
results$rotation    # loadings matrix
# Make a simple scree plot
plot(results$importance[2,1:10], type="b",
main="Proportion of Explained Variance",
xlab="PC", ylab="Proportion of Variance")
# Plot the cumulative proportion of variance
plot(results$importance[3,1:10], type="b",
main="Cumulative Proportion of Variance",
xlab="PC", ylab="Proportion of Variance")
# Make a simple scores plot
plot(pca$x[,1], pca$x[,2], type='p', cex=0, pch=20,
main="Scores Plot", xlab="PC1", ylab="PC2")
# add text labels to data points
text(pca$x[,1], pca$x[,2], labels=rownames(pca$x), cex=1.0)
abline(h=0, v=0, col="red")
# Make a simple loadings plot (variance among variables)
plot(pca$rotation[,1], pca$rotation[,2], type='p', cex=0.5, pch=20,
main="Loadings Plot", xlab="PC1", ylab="PC2")
# add text labels for data points
text(pca$rotation[,1], pca$rotation[,2], labels=rownames(pca$rotation), cex=1.0)
abline(h=0, v=0, col="red")
scree.data <- as.data.frame(results$importance)
score.data <- as.data.frame(results$x)
loadings.data <- as.data.frame(results$rotation)
# Save PCA results to file (we'll use later)
write.csv(scree.data, "pca_scree.csv")
write.csv(score.data, "pca_scores.csv")
write.csv(loadings.data, "pca_loadings.csv")
plot(loadings.data$PC1, loadings.data$PC2)
abline(v=0.09, col="red")
abline(v=-0.09, col="red")
abline(h=0.09, col="red")
abline(h=-0.09, col="red")
# Make a new data frame with PC1, PC2, and PC3 loadings
loadings.PC1.PC2 <- loadings.data[,1:3]
loadings.PC1.PC2[1:6,1:3]  # look at the first few rows
# subset significant loadings
loadings.sig <- subset(loadings.PC1.PC2,
PC1 > 0.09 | PC1 < -0.09 |
PC2 > 0.09 | PC2 < -0.09)
# sanity check - plot the results
plot(loadings.sig$PC1, loadings.sig$PC2)
# PC1 loadings
loadings.sig$pc1.change <-
ifelse(loadings.sig$PC1 > 0.09,"UP",
ifelse(loadings.sig$PC1 < -0.09,"DOWN",
"none"))
# PC2 loadings
loadings.sig$pc2.change <-
ifelse(loadings.sig$PC2 > 0.09,"UP",
ifelse(loadings.sig$PC2 < -0.09,"DOWN",
"none"))
# Number of signficant PC1 loadings
length(which(loadings.sig$pc1.change=="UP"))
length(which(loadings.sig$pc1.change=="DOWN"))
length(which(loadings.sig$pc1.change=="none"))
# Number of signficant PC2 loadings
length(which(loadings.sig$pc2.change=="UP"))
length(which(loadings.sig$pc2.change=="DOWN"))
length(which(loadings.sig$pc2.change=="none"))
# Write significant loadings to file for later use.
write.csv(loadings.sig, "sig_loadings.csv")
# Merge significant PC1 and PC2 loadings with raw data
# Note: use missing values corrected data
pca.sig.vars <- merge(dat2, loadings.sig, by="row.names")
# use the "arrange" function in the plyr package to order
library(plyr)
pca.sig.vars <- arrange(pca.sig.vars, pc1.change, pc2.change)
# Re-assign row names and delete "Row.names" column
row.names(pca.sig.vars) <- pca.sig.vars$Row.names
pca.sig.vars$Row.names <- NULL
# Write the results to file for later use.
write.csv(pca.sig.vars, "dat_sig_loadings.csv")
# Set working directory
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# Import data
dat1 <- read.csv("DryAlmondDryPistachio.csv", header=T, row.names=1,)
# Import data
dat1 <- read.csv("DryAlmond&Pistachio.csv", header=T, row.names=1,)
# Import data
dat1 <- read.csv("DryAlmondandPistachio.csv", header=T, row.names=1,)
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# Import data
dat1 <- read.csv("DryAlmondandPistachio.csv", header=T, row.names=1,)
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# Import data
dat1 <- read.csv("DryAlmondandPistachio.csv", header=T, row.names=1,)
# Import data
dat1 <- read.csv("DryAlmondandPistachio.csv", header=T, row.names=1,)
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# Import data
dat1 <- read.csv("DataFormatted.csv", header=T, row.names=1,)
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
dat1 <- read.csv("DataFormattedV2.csv", header=T, row.names=1,)
View(dat1)
View(dat1)
dat1 <- read.csv("DataFormattedV2.csv", header=T, row.names=1,)
dat1 <- read.csv("DataFormattedV2.csv", header=T, row.names=1,)
dat1 <- read.csv("DataFormattedV2.csv", header=T, row.names=1,)
dat1[1:6,1:4]  # look at the first few rows
#ck the structure of the data frame needs to be num
str(dat1)
#ck the structure of the data frame needs to be num
str(dat1[1:5,])
#ck the structure of the data frame needs to be num
str(dat1[1:5,1:5])
# This function will find the minimum value greater than zero
# and divide that value by two
replacezero = function(x) "[<-"(x, !x | is.na(x), min(x[x > 0], na.rm = TRUE) / 2)
# Apply function across rows
dat2 <- as.data.frame(t(apply(dat1, 1, replacezero)))
dat2[1:6,1:4]  # look at the first few rows
# Log transform the data (base 2 log)
logdata <- log(dat2, 2)
# Function for pareto scaling
paretoscale <- function(z) {
rowmean <- apply(z, 1, mean) # row means
rowsd <- apply(z, 1, sd)  # row standard deviation
rowsqrtsd <- sqrt(rowsd) # sqrt of sd
rv <- sweep(z, 1, rowmean,"-")  # mean center
rv <- sweep(rv, 1, rowsqrtsd, "/")  # dividing by sqrtsd
return(rv)
}
# Pareto scale log transformed data
logdata.pareto <- paretoscale(logdata)
# Run PCA (note use of "t" to transpose matrix)
pca <- prcomp(t(logdata.pareto), center=F, scale=F)
# Create a container called "results" for PCA results
results <- summary(pca)
results$importance  # summary table of explained variance
results$x           # scores matrix
View(dat2)
dat1 <- read.csv("DataFormattedV2.csv", header=T, row.names=1,)
dat1 <- read.csv("DataFormattedV2.csv", header=T, row.names=1,)
dat1[1:6,1:4]  # look at the first few rows
#ck the structure of the data frame needs to be num
str(dat1[1:5,1:5])
# This function will find the minimum value greater than zero
# and divide that value by two
replacezero = function(x) "[<-"(x, !x | is.na(x), min(x[x > 0], na.rm = TRUE) / 2)
# Apply function across rows
dat2 <- as.data.frame(t(apply(dat1, 1, replacezero)))
dat2[1:6,1:4]  # look at the first few rows
# Log transform the data (base 2 log)
logdata <- log(dat2, 2)
# Function for pareto scaling
paretoscale <- function(z) {
rowmean <- apply(z, 1, mean) # row means
rowsd <- apply(z, 1, sd)  # row standard deviation
rowsqrtsd <- sqrt(rowsd) # sqrt of sd
rv <- sweep(z, 1, rowmean,"-")  # mean center
rv <- sweep(rv, 1, rowsqrtsd, "/")  # dividing by sqrtsd
return(rv)
}
# Pareto scale log transformed data
logdata.pareto <- paretoscale(logdata)
# Run PCA (note use of "t" to transpose matrix)
pca <- prcomp(t(logdata.pareto), center=F, scale=F)
# Create a container called "results" for PCA results
results <- summary(pca)
results$importance  # summary table of explained variance
results$x           # scores matrix
results$rotation    # loadings matrix
# Make a simple scree plot
plot(results$importance[2,1:10], type="b",
main="Proportion of Explained Variance",
xlab="PC", ylab="Proportion of Variance")
# Plot the cumulative proportion of variance
plot(results$importance[3,1:10], type="b",
main="Cumulative Proportion of Variance",
xlab="PC", ylab="Proportion of Variance")
# Make a simple scores plot
plot(pca$x[,1], pca$x[,2], type='p', cex=0, pch=20,
main="Scores Plot", xlab="PC1", ylab="PC2")
# add text labels to data points
text(pca$x[,1], pca$x[,2], labels=rownames(pca$x), cex=1.0)
abline(h=0, v=0, col="red")
# Make a simple loadings plot (variance among variables)
plot(pca$rotation[,1], pca$rotation[,2], type='p', cex=0.5, pch=20,
main="Loadings Plot", xlab="PC1", ylab="PC2")
# add text labels for data points
text(pca$rotation[,1], pca$rotation[,2], labels=rownames(pca$rotation), cex=1.0)
abline(h=0, v=0, col="red")
scree.data <- as.data.frame(results$importance)
score.data <- as.data.frame(results$x)
loadings.data <- as.data.frame(results$rotation)
# Save PCA results to file (we'll use later)
write.csv(scree.data, "pca_scree.csv")
write.csv(score.data, "pca_scores.csv")
write.csv(loadings.data, "pca_loadings.csv")
plot(loadings.data$PC1, loadings.data$PC2)
abline(v=0.09, col="red")
abline(v=-0.09, col="red")
abline(h=0.09, col="red")
abline(h=-0.09, col="red")
# Make a new data frame with PC1, PC2, and PC3 loadings
loadings.PC1.PC2 <- loadings.data[,1:3]
loadings.PC1.PC2[1:6,1:3]  # look at the first few rows
# subset significant loadings
loadings.sig <- subset(loadings.PC1.PC2,
PC1 > 0.09 | PC1 < -0.09 |
PC2 > 0.09 | PC2 < -0.09)
# sanity check - plot the results
plot(loadings.sig$PC1, loadings.sig$PC2)
# PC1 loadings
loadings.sig$pc1.change <-
ifelse(loadings.sig$PC1 > 0.09,"UP",
ifelse(loadings.sig$PC1 < -0.09,"DOWN",
"none"))
# PC2 loadings
loadings.sig$pc2.change <-
ifelse(loadings.sig$PC2 > 0.09,"UP",
ifelse(loadings.sig$PC2 < -0.09,"DOWN",
"none"))
# Number of signficant PC1 loadings
length(which(loadings.sig$pc1.change=="UP"))
length(which(loadings.sig$pc1.change=="DOWN"))
length(which(loadings.sig$pc1.change=="none"))
# Number of signficant PC2 loadings
length(which(loadings.sig$pc2.change=="UP"))
length(which(loadings.sig$pc2.change=="DOWN"))
length(which(loadings.sig$pc2.change=="none"))
# Write significant loadings to file for later use.
write.csv(loadings.sig, "sig_loadings.csv")
# Merge significant PC1 and PC2 loadings with raw data
# Note: use missing values corrected data
pca.sig.vars <- merge(dat2, loadings.sig, by="row.names")
# use the "arrange" function in the plyr package to order
library(plyr)
pca.sig.vars <- arrange(pca.sig.vars, pc1.change, pc2.change)
# Re-assign row names and delete "Row.names" column
row.names(pca.sig.vars) <- pca.sig.vars$Row.names
pca.sig.vars$Row.names <- NULL
# Write the results to file for later use.
write.csv(pca.sig.vars, "dat_sig_loadings.csv")
setwd("D:/telework transfer files/R project GC-MSExample  Beck 2021 vs2")
# import scores matrix
data <- read.csv("pca_scores.csv", header=T)
# subset to include only PC1 to PC3 scores
data <- data[, c(1:4)]
# look at first few rows
data[1:6,1:4]
# Get variance percentages for first 3 PC's
screedat <- read.csv("pca_scree.csv", header=T)
var1 <- round(screedat[2,2:4] * 100, 1)
# Change "X" column to "Sample"
colnames(data)[colnames(data)=="X"] <- "Sample"
View(data)
# Add Group label to the data frame
Group <- c(rep("DryPistachio", 12),
rep("DryAlmond", 12))
data <- cbind(data, Group)
View(data)
# load ggplot2
library(ggplot2)
# Make custom theme for ggplot
my.theme <- theme(axis.text = element_text(colour="black", size=15),
text = element_text(size=16),
title = element_text(size=18, face="bold", vjust=2),
panel.background = element_rect(fill = 'gray99',
colour = "black",
size=0.5),
axis.title.x=  element_text(vjust=-0.45),
axis.title.y = element_text(vjust=1.2),
axis.ticks = element_line(colour="black"),
axis.line = element_line(),
panel.grid.major = element_line(colour = "gray40", linetype="dotted"),
panel.grid.minor = element_line(colour = "gray40", linetype="dashed"),
legend.justification=c(1,1),
legend.position=c(1,1),
legend.title=element_blank(),
legend.text = element_text(size = 14))
# check variances for PC1 and PC2
var1
# Calculate 95% ellipse values for PC1,PC2
library(ellipse)
centroids <- aggregate(cbind(PC1,PC2)~Group,data,mean)
# make plot for PC1 vs. PC2
g1 <-
ggplot(data, aes(PC1, PC2)) +
geom_hline(yintercept = 0, colour = "gray50") +
geom_vline(xintercept = 0, colour = "gray50") +
# geom_polygon(data=conf.rgn1,  # this did not work
#              aes(fill=Group), colour="black", alpha = 0.2,
#              linetype="blank", show.legend=FALSE) +
geom_point(aes(shape=Group, bg=Group), colour="black", size=4.5) +
geom_text(aes(label=data$Sample), colour="black",
size=4, hjust=-0.25, vjust=1) +
#this is the correct way to apply geom polygon in line 88
stat_ellipse(geom = "polygon",
aes(fill = Group),
alpha = 0.25)+
scale_fill_brewer(palette = "Dark2") +
scale_shape_manual(values=c(21,22,23,24)) +
ggtitle("PCA Scores Plot") +
xlab("PC 1 (87.9%)") + #from var1 above
ylab("PC 2 (4.7%)") +
my.theme +
theme(legend.position=c(0.30,0.25))
# draw scores plot
g1
# make plot for PC1 vs. PC2
g1 <-
ggplot(data, aes(PC1, PC2)) +
geom_hline(yintercept = 0, colour = "gray50") +
geom_vline(xintercept = 0, colour = "gray50") +
# geom_polygon(data=conf.rgn1,  # this did not work
#              aes(fill=Group), colour="black", alpha = 0.2,
#              linetype="blank", show.legend=FALSE) +
geom_point(aes(shape=Group, bg=Group), colour="black", size=4.5) +
geom_text(aes(label=data$Sample), colour="black",
size=4, hjust=-0.25, vjust=1) +
#this is the correct way to apply geom polygon in line 88
stat_ellipse(geom = "polygon",
aes(fill = Group),
alpha = 0.25)+
scale_fill_brewer(palette = "Dark2") +
scale_shape_manual(values=c(21,22,23,24)) +
ggtitle("PCA Scores Plot") +
xlab("PC 1 (87.9%)") + #from var1 above
ylab("PC 2 (4.7%)") +
my.theme +
theme(legend.position=c(0.20,0.25))
# draw scores plot
g1
# make plot for PC1 vs. PC2
g1 <-
ggplot(data, aes(PC1, PC2)) +
geom_hline(yintercept = 0, colour = "gray50") +
geom_vline(xintercept = 0, colour = "gray50") +
# geom_polygon(data=conf.rgn1,  # this did not work
#              aes(fill=Group), colour="black", alpha = 0.2,
#              linetype="blank", show.legend=FALSE) +
geom_point(aes(shape=Group, bg=Group), colour="black", size=4.5) +
geom_text(aes(label=data$Sample), colour="black",
size=4, hjust=-0.25, vjust=1) +
#this is the correct way to apply geom polygon in line 88
stat_ellipse(geom = "polygon",
aes(fill = Group),
alpha = 0.25)+
scale_fill_brewer(palette = "Dark2") +
scale_shape_manual(values=c(21,22,23,24)) +
ggtitle("PCA Scores Plot") +
xlab("PC 1 (87.9%)") + #from var1 above
ylab("PC 2 (4.7%)") +
my.theme +
theme(legend.position=c(0.25,0.25))
# draw scores plot
g1
